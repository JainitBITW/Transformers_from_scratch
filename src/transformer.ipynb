{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import copy\n",
    "import re \n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"This function preprocesses the sentence\"\"\"\n",
    "    #lowercase the sentence\n",
    "    sentence = sentence.lower()\n",
    "    #split the sentence into word\n",
    "    puntuations = r\" !\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    sentence = re.sub(puntuations, r\" \\1 \", sentence)\n",
    "    #replace continous numbers wiith <num>\n",
    "    sentence = re.sub(r\"\\d+\", \"<num>\", sentence)\n",
    "    #replace multiple spaces with single space\n",
    "    sentence = re.sub(r\" +\", \" \", sentence)\n",
    "    #split the sentence into words\n",
    "    return sentence \n",
    "    \n",
    "\n",
    "def preprocess_corpus(sentences , threshold = 5):\n",
    "    \"\"\"This function is for all sentences \"\"\"\n",
    "    \n",
    "    word_freq = {}\n",
    "    # first preprocess the sentences \n",
    "    tokenised_sentences = []\n",
    "    for i , sentence in enumerate(sentences):\n",
    "        #lowercase the sentence\n",
    "        sentence = preprocess_sentence(sentence)\n",
    "        #split the sentence into words\n",
    "        words = sentence.split()\n",
    "        tokenised_sentences.append(words)\n",
    "        #count the frequency of each word\n",
    "        for word in words:\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += 1\n",
    "            else:\n",
    "                word_freq[word] = 1\n",
    "    \n",
    "    #remove the words with frequency less than threshold\n",
    "    #replace the words with frequency less than threshold with <unk>\n",
    "    vocab = [\"<pad>\" , \"<sos>\" , \"<eos>\" , \"<unk>\"]\n",
    "    for i , sentence in enumerate(tokenised_sentences):\n",
    "        for j , word in enumerate(sentence):\n",
    "            if word_freq[word] < threshold:\n",
    "                tokenised_sentences[i][j] = \"<unk>\"\n",
    "    \n",
    "    #create the vocab\n",
    "    for word in word_freq:\n",
    "        if word_freq[word] >= threshold:\n",
    "            vocab.append(word)\n",
    "            \n",
    "    #create the word2idx and idx2word\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for i , word in enumerate(vocab):\n",
    "        word2idx[word] = i\n",
    "        idx2word[i] = word\n",
    "    \n",
    "    return  word2idx , idx2word , vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train and test sentences with labels \n",
    "data = {\"train\":{\"en\":[],\"fr\":[]},\"test\":{\"en\":[],\"fr\":[]},\"dev\":{\"en\":[],\"fr\":[]}}\n",
    "for type in [\"train\" , \"test\" , \"dev\"]:\n",
    "    for lang in [\"en\" , \"fr\"]:\n",
    "        with open(f\"../data/{type}.{lang}\" , \"r\") as f:\n",
    "            for line in f:\n",
    "                data[type][lang].append(line.strip())\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokeniser():\n",
    "    def __init__(self , word2idx , idx2word):\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "    \n",
    "    def __call__(self , sentences, truncation = 100 , padding = True):\n",
    "        \"\"\"This function tokenises the sentence\"\"\"\n",
    "        #first preprocess the sentences\n",
    "        max_len = 0\n",
    "        tokenised_sentences = []\n",
    "        for sentence in sentences:\n",
    "            #lowercase the sentence\n",
    "            sentence = preprocess_sentence(sentence)\n",
    "            #split the sentence into words\n",
    "            words = sentence.split()\n",
    "            tokenised_sentences.append(words)\n",
    "            if len(tokenised_sentences[-1] ) > truncation-2:\n",
    "                tokenised_sentences[-1] = tokenised_sentences[-1][:truncation]\n",
    "                tokenised_sentences[-1]= [\"<sos>\"] + tokenised_sentences[-1] + [\"<eos>\"]\n",
    "            else :\n",
    "                tokenised_sentences[-1]= [\"<sos>\"] + tokenised_sentences[-1] + [\"<eos>\"]\n",
    "            if len(tokenised_sentences[-1]) > max_len:\n",
    "                max_len = len(tokenised_sentences[-1])\n",
    "            \n",
    "        \n",
    "        #convert the words into indices\n",
    "        indices, attention_mask = [] , []\n",
    "        for sentence in tokenised_sentences:\n",
    "            index = []\n",
    "            for word in sentence:\n",
    "                if word in self.word2idx:\n",
    "                    index.append(self.word2idx[word])\n",
    "                else:\n",
    "                    index.append(self.word2idx[\"<unk>\"])\n",
    "            #pad the sentences\n",
    "            \n",
    "            if padding:\n",
    "                \n",
    "                index = index + [self.word2idx[\"<pad>\"]] * (max_len - len(index))\n",
    "            index = torch.tensor(index)\n",
    "            indices.append(index)\n",
    "        \n",
    "        \n",
    "        #create the attention mask\n",
    "        for index in indices:\n",
    "            attention_mask.append(torch.where(index == self.word2idx[\"<pad>\"] , 0 , 1))\n",
    "        \n",
    "        #convert the indices into tensor\n",
    "        indices = torch.stack(indices)\n",
    "        attention_mask = torch.stack(attention_mask)\n",
    "        return indices , attention_mask\n",
    "        \n",
    "        \n",
    "    def decode(self , indices):\n",
    "        \"\"\"This function decodes the indices into words\"\"\"\n",
    "        words = []\n",
    "        for index in indices:\n",
    "            words.append(self.idx2word[index])\n",
    "        return words\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_corpus = data[\"train\"][\"en\"] + data[\"dev\"][\"en\"]\n",
    "french_corpus = data[\"train\"][\"fr\"] + data[\"dev\"][\"fr\"]\n",
    "\n",
    "en_word2idx , en_idx2word , en_vocab = preprocess_corpus(english_corpus, threshold = 5)\n",
    "fr_word2idx , fr_idx2word , fr_vocab = preprocess_corpus(french_corpus , threshold = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokeniser = Tokeniser(en_word2idx , en_idx2word)\n",
    "fr_tokeniser = Tokeniser(fr_word2idx , fr_idx2word)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self , d_model , d_ff , dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model , d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff , d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self , x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self , d_model , num_heads , dropout = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.linear_q = nn.Linear(d_model , d_model)\n",
    "        self.linear_k = nn.Linear(d_model , d_model)\n",
    "        self.linear_v = nn.Linear(d_model , d_model)\n",
    "        self.linear_o = nn.Linear(d_model , d_model)\n",
    "    \n",
    "    def forward(self , query , key , value , mask = None):\n",
    "        batch_size = query.size(0)\n",
    "        #query = [batch_size , seq_len , d_model]\n",
    "        #key = [batch_size , seq_len , d_model]\n",
    "        #value = [batch_size , seq_len , d_model]\n",
    "        #mask = [batch_size , seq_len , seq_len]\n",
    "        \n",
    "        #linear transformation\n",
    "        query = self.linear_q(query)\n",
    "        key = self.linear_k(key)\n",
    "        value = self.linear_v(value)\n",
    "        #query = [batch_size , seq_len , d_model]\n",
    "        #key = [batch_size , seq_len , d_model]\n",
    "        #value = [batch_size , seq_len , d_model]\n",
    "        \n",
    "        #split the query , key and value into num_heads\n",
    "        query = query.view(batch_size , -1 , self.num_heads , self.d_k)\n",
    "        key = key.view(batch_size , -1 , self.num_heads , self.d_k)\n",
    "        value = value.view(batch_size , -1 , self.num_heads , self.d_k)\n",
    "        #query = [batch_size , seq_len , num_heads , d_k]\n",
    "        #key = [batch_size , seq_len , num_heads , d_k]\n",
    "        #value = [batch_size , seq_len , num_heads , d_k]\n",
    "        \n",
    "        #transpose the query , key and value\n",
    "        query = query.transpose(1 , 2)\n",
    "        key = key.transpose(1 , 2)\n",
    "        value = value.transpose(1 , 2)\n",
    "        #query = [batch_size , num_heads , seq_len , d_k]\n",
    "        #key = [batch_size , num_heads , seq_len , d_k]\n",
    "        #value = [batch_size , num_heads , seq_len , d_k]\n",
    "        \n",
    "        #calculate the scores\n",
    "        scores = torch.matmul(query , key.transpose(-2 , -1))\n",
    "        #scores = [batch_size , num_heads , seq_len , seq_len]\n",
    "        \n",
    "        #scale the scores\n",
    "        scores = scores / math.sqrt(self.d_k)\n",
    "\n",
    "        #apply softmax\n",
    "        if mask is not None:\n",
    "            \n",
    "            mask = mask.unsqueeze(1)\n",
    "            mask = mask.expand_as(scores)\n",
    "            mask.to(scores.device)\n",
    "            scores = scores.masked_fill(mask == 0 , -1e9)\n",
    "            \n",
    "        scores = F.softmax(scores , dim = -1)\n",
    "        scores = self.dropout(scores)\n",
    "        #scores = [batch_size , num_heads , seq_len , seq_len]\n",
    "        \n",
    "        #apply attention\n",
    "        context = torch.matmul(scores , value)\n",
    "        #context = [batch_size , num_heads , seq_len , d_k]\n",
    "        \n",
    "        #concat the heads\n",
    "        context = context.transpose(1 , 2)\n",
    "        #context = [batch_size , seq_len , num_heads , d_k]\n",
    "        context = context.contiguous().view(batch_size , -1 , self.d_model)\n",
    "        #context = [batch_size , seq_len , d_model]\n",
    "        \n",
    "        #linear transformation\n",
    "        context = self.linear_o(context)\n",
    "        #context = [batch_size , seq_len , d_model]\n",
    "        return context\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self , d_model , eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.eps = eps\n",
    "        self.a_2 = nn.Parameter(torch.ones(self.d_model))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(self.d_model))\n",
    "    \n",
    "    def forward(self , x):\n",
    "        mean = x.mean(-1 , keepdim = True)\n",
    "        std = x.std(-1 , keepdim = True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model , num_heads , d_ff , num_layers , dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model , num_heads , dropout)\n",
    "        self.feed_forward = FeedForward(d_model , d_ff , dropout)\n",
    "        self.layer_norm1 = LayerNorm(d_model)\n",
    "        self.layer_norm2 = LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self , x , mask = None):\n",
    "        batch, seq_len, d_model = x.size()\n",
    "        if mask is not None: \n",
    "            mask = mask.unsqueeze(1)\n",
    "            mask = mask.expand(batch, seq_len, seq_len)\n",
    "        \n",
    "        x_m = self.multi_head_attention(x , x , x , mask)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm1(x + x_m)\n",
    "        x_f = self.feed_forward(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm2(x + x_f)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "        #x = [batch_size , seq_len , d_model]\n",
    "        #mask = [batch_size , seq_len , seq_len]\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model , num_heads , d_ff , num_layers , dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.multi_head_attention1 = MultiHeadAttention(d_model , num_heads , dropout)\n",
    "        self.multi_head_attention2 = MultiHeadAttention(d_model , num_heads , dropout)\n",
    "        self.feed_forward = FeedForward(d_model , d_ff , dropout)\n",
    "        self.layer_norm1 = LayerNorm(d_model)\n",
    "        self.layer_norm2 = LayerNorm(d_model)\n",
    "        self.layer_norm3 = LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self , x , encoder_output,src_mask=None ,tgt_mask = None):\n",
    "        #x = [batch_size , seq_len , d_model]\n",
    "        #encoder_output = [batch_size , seq_len , d_model]\n",
    "        #src_mask = [batch_size , seq_len ]\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        look_ahead_mask = torch.tril(torch.ones(x.size(1) , x.size(1))).unsqueeze(0)\n",
    "        look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "        x_m = self.multi_head_attention1(x , x , x , look_ahead_mask)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm1(x + x_m)\n",
    "        cross_mask = src_mask.unsqueeze(1).expand(batch_size , seq_len , src_mask.size(1)) \n",
    "        cross_mask = cross_mask.to(x.device)\n",
    "        x_m = self.multi_head_attention2(x , encoder_output , encoder_output , cross_mask)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm2(x + x_m)\n",
    "        x_f = self.feed_forward(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm3(x + x_f)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self , d_model , num_heads , d_ff , num_layers , dropout = 0.1 , en_embedding = None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model , num_heads , d_ff , num_layers , dropout) for _ in range(num_layers)])\n",
    "        self.en_embedding = en_embedding\n",
    "    \n",
    "    def forward(self , x , mask = None):\n",
    "        x = self.en_embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x , mask)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self , d_model , num_heads , d_ff , num_layers , dropout = 0.1 , fr_embedding = None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.num_layers = num_layers\n",
    "        self.fr_embedding = fr_embedding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model , num_heads , d_ff , num_layers , dropout) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self , x , encoder_output , src_mask = None , tgt_mask = None):\n",
    "        x = self.fr_embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x , encoder_output , src_mask , tgt_mask)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self , d_model , num_heads , d_ff , num_layers , dropout = 0.1 , en_vocab = en_vocab , fr_vocab = fr_vocab):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.en_embedding = nn.Embedding(len(en_vocab) , d_model)\n",
    "        self.fr_embedding = nn.Embedding(len(fr_vocab) , d_model)\n",
    "        self.encoder = Encoder(d_model , num_heads , d_ff , num_layers , dropout, self.en_embedding)\n",
    "        self.decoder = Decoder(d_model , num_heads , d_ff , num_layers , dropout, self.fr_embedding)\n",
    "        self.linear = nn.Linear(d_model , len(fr_vocab))\n",
    "    \n",
    "    def forward(self , src , tgt , src_mask = None , tgt_mask = None):\n",
    "        \n",
    "        encoder_output = self.encoder(src , src_mask)\n",
    "        decoder_output = self.decoder(tgt , encoder_output , src_mask , tgt_mask)\n",
    "        \n",
    "        output = self.linear(decoder_output)\n",
    "        return output\n",
    "    \n",
    "    def translate(self , src , src_mask = None , max_len = 100):\n",
    "        \n",
    "        encoder_output = self.encoder(src , src_mask)\n",
    "        tgt = torch.zeros(src.size(0) , 1).long().to(src.device)\n",
    "        for i in range(max_len):\n",
    "            tgt_mask = torch.tril(torch.ones(tgt.size(1) , tgt.size(1))).unsqueeze(0).to(src.device)\n",
    "            decoder_output = self.decoder(tgt , encoder_output , src_mask , tgt_mask)\n",
    "            output = self.linear(decoder_output)\n",
    "            output = output[: , -1 , :]\n",
    "            output = torch.argmax(output , dim = -1)\n",
    "            tgt = torch.cat([tgt , output.unsqueeze(1)] , dim = 1)\n",
    "        return tgt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "d_model = 300\n",
    "num_heads = 6\n",
    "d_ff = 300\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_input_ids , en_attention_mask = en_tokeniser(data[\"train\"][\"en\"])\n",
    "fr_input_ids , fr_attention_mask = fr_tokeniser(data[\"train\"][\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self , en_input_ids , en_attention_mask , fr_input_ids , fr_attention_mask):\n",
    "        self.en_input_ids = en_input_ids\n",
    "        self.en_attention_mask = en_attention_mask\n",
    "        self.fr_input_ids = fr_input_ids\n",
    "        self.fr_attention_mask = fr_attention_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.en_input_ids)\n",
    "    \n",
    "    def __getitem__(self , idx):\n",
    "        return ((self.en_input_ids[idx] , self.en_attention_mask[idx]) , (self.fr_input_ids[idx] , self.fr_attention_mask[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(en_input_ids , en_attention_mask , fr_input_ids , fr_attention_mask)\n",
    "en_input_ids_dev, en_attention_mask_dev = en_tokeniser(data[\"dev\"][\"en\"])\n",
    "fr_input_ids_dev, fr_attention_mask_dev = fr_tokeniser(data[\"dev\"][\"fr\"])\n",
    "dev_dataset = TranslationDataset(en_input_ids_dev , en_attention_mask_dev , fr_input_ids_dev , fr_attention_mask_dev)\n",
    "en_input_ids_test, en_attention_mask_test = en_tokeniser(data[\"test\"][\"en\"])\n",
    "fr_input_ids_test, fr_attention_mask_test = fr_tokeniser(data[\"test\"][\"fr\"])\n",
    "test_dataset = TranslationDataset(en_input_ids_test , en_attention_mask_test , fr_input_ids_test , fr_attention_mask_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders= {\"train\":DataLoader(train_dataset , batch_size = batch_size , shuffle = True , ) , \"test\" : DataLoader(test_dataset , batch_size = batch_size , shuffle = False , ) , \"dev\":DataLoader(dev_dataset , batch_size = batch_size , shuffle = False ,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitDataset(pl.LightningDataModule):\n",
    "    def __init__(self , dataloaders):\n",
    "        super().__init__()\n",
    "        self.dataloaders = dataloaders\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.dataloaders[\"train\"]\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.dataloaders[\"dev\"]\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.dataloaders[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/jainit/miniconda3/envs/torchy/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home2/jainit/miniconda3/envs/torchy/lib/python3.11/ ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "class LitTransformer(pl.LightningModule):\n",
    "    def __init__(self, d_model , num_heads , d_ff , num_layers , dropout , en_vocab , fr_vocab):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.en_vocab = en_vocab\n",
    "        self.fr_vocab = fr_vocab\n",
    "        self.transformer = Transformer(d_model , num_heads , d_ff , num_layers , dropout , en_vocab , fr_vocab)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index = self.fr_vocab.index(\"<pad>\"))\n",
    "        \n",
    "    def forward(self , src , tgt , src_mask = None , tgt_mask = None):\n",
    "        return self.transformer(src , tgt , src_mask , tgt_mask)\n",
    "    \n",
    "    def training_step(self , batch , batch_idx):\n",
    "        src , tgt = batch\n",
    "        src_input_ids , src_attention_mask = src\n",
    "        tgt_input_ids , tgt_attention_mask = tgt\n",
    "        output = self(src_input_ids , tgt_input_ids[:,:-1] , src_attention_mask , tgt_attention_mask[:,:-1])\n",
    "        output = output.contiguous().view(-1 , output.size(-1))\n",
    "        tgt_input_ids = tgt_input_ids[:,1:].contiguous().view(-1)\n",
    "        loss = self.criterion(output , tgt_input_ids)\n",
    "        self.log(\"train_loss\" , loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self , batch , batch_idx):\n",
    "        src , tgt = batch\n",
    "        src_input_ids , src_attention_mask = src\n",
    "        tgt_input_ids , tgt_attention_mask = tgt\n",
    "        output = self(src_input_ids , tgt_input_ids[:,:-1] , src_attention_mask , tgt_attention_mask[:,:-1])\n",
    "        output = output.contiguous().view(-1 , output.size(-1))\n",
    "        tgt_input_ids = tgt_input_ids[:,1:].contiguous().view(-1)\n",
    "        loss = self.criterion(output , tgt_input_ids)\n",
    "        self.log(\"val_loss\" , loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self , batch , batch_idx):\n",
    "        src , tgt = batch\n",
    "        src_input_ids , src_attention_mask = src\n",
    "        tgt_input_ids , tgt_attention_mask = tgt\n",
    "        output = self(src_input_ids , tgt_input_ids[:,:-1] , src_attention_mask , tgt_attention_mask[:,:-1])\n",
    "        output = output.contiguous().view(-1 , output.size(-1))\n",
    "        tgt_input_ids = tgt_input_ids[:,1:].contiguous().view(-1)\n",
    "        loss = self.criterion(output , tgt_input_ids)\n",
    "        self.log(\"test_loss\" , loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters() , lr = 0.0001)\n",
    "    \n",
    "    def translate(self , src , src_mask = None , max_len = 100):\n",
    "        return self.transformer.translate(src , src_mask , max_len)\n",
    "    \n",
    "    \n",
    "model = LitTransformer(d_model , num_heads , d_ff , num_layers , dropout , en_vocab , fr_vocab)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=epochs  , enable_progress_bar=True, logger=None ,devices =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/jainit/miniconda3/envs/torchy/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home2/jainit/miniconda3/envs/torchy/lib/python3.11/ ...\n",
      "  rank_zero_warn(\n",
      "/home2/jainit/miniconda3/envs/torchy/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /home2/jainit/LR_LLM/Transformer/src/lightning_logs/version_1000421/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | transformer | Transformer      | 10.7 M\n",
      "1 | criterion   | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "10.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.7 M    Total params\n",
      "42.732    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfbd12e57a24d19882315440c933d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/jainit/miniconda3/envs/torchy/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home2/jainit/miniconda3/envs/torchy/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8962cd852d9a4528b11fb7bbf5d48f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023017c935e7403781e84baefd524c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c4790318154718a29a7ce009e85519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model , LitDataset(dataloaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training using normal pytorch\n",
    "# model = Transformer(d_model , num_heads , d_ff , num_layers , dropout , en_vocab , fr_vocab)\n",
    "# model = model.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters() , lr = 1e-4)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index = fr_word2idx[\"<pad>\"])\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer , patience = 2 , verbose = True)\n",
    "\n",
    "# def train(model , optimizer , criterion , scheduler , dataloaders , epochs , device):\n",
    "#     steps = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         for phase in [\"train\" , \"dev\"]:\n",
    "#             if phase == \"train\":\n",
    "#                 model.train()\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "#             epoch_loss = 0\n",
    "#             for ((en_input_ids , en_attention_mask) , (fr_input_ids , fr_attention_mask)) in dataloaders[phase]:\n",
    "#                 steps += 1\n",
    "#                 en_input_ids = en_input_ids.to(device)\n",
    "#                 en_attention_mask = en_attention_mask.to(device)\n",
    "#                 fr_input_ids = fr_input_ids.to(device)\n",
    "#                 fr_attention_mask = fr_attention_mask.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 with torch.set_grad_enabled(phase == \"train\"):\n",
    "#                     output = model(en_input_ids , fr_input_ids[:,:-1] , en_attention_mask , fr_attention_mask[:,:-1])\n",
    "#                     output = output.contiguous().view(-1 , output.size(-1))\n",
    "#                     fr_input_ids = fr_input_ids[:,1:].contiguous().view(-1)\n",
    "#                     loss = criterion(output , fr_input_ids)\n",
    "#                     if phase == \"train\":\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "#                 epoch_loss += loss.item()\n",
    "#                 if steps % 100 == 0:\n",
    "#                     print(f\"Epoch : {epoch+1} , Phase : {phase} , Loss : {loss.item()}\")\n",
    "#             epoch_loss = epoch_loss / len(dataloaders[phase])\n",
    "#             if phase == \"train\":\n",
    "#                 print(f\"Epoch : {epoch+1} , Train Loss : {epoch_loss}\")\n",
    "#             else:\n",
    "#                 print(f\"Epoch : {epoch+1} , Dev Loss : {epoch_loss}\")\n",
    "#                 scheduler.step(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model , optimizer , criterion , scheduler , dataloaders , epochs , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
